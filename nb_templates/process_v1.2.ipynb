{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[set-up\\], imports\n",
    "Reminder (if working on the notebook server): make sure your copy of `pint_pal` is up to date and you're working on a development branch, e.g. `psr/J1234+5678/jks`. See README for more details. If not working on the notebook server, you may need to update required software packages (`pint`, `enterprise`, `enterprise_extensions`) according to requirements in `setup.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pint_pal.par_checker as pc\n",
    "import pint_pal.dmx_utils as du\n",
    "import pint_pal.lite_utils as lu\n",
    "import pint_pal.noise_utils as nu\n",
    "import pint_pal.plot_utils as pu\n",
    "from pint_pal.ftester import run_Ftests\n",
    "from pint_pal.utils import resid_stats, pdf_writer, apply_cut_select\n",
    "from pint_pal.utils import check_recentness_excision, check_recentness_noise\n",
    "from pint_pal.timingconfiguration import TimingConfiguration\n",
    "from astropy import log\n",
    "from pint.fitter import ConvergenceFailure\n",
    "import pint.fitter\n",
    "from pint.utils import dmxparse\n",
    "import os\n",
    "import copy\n",
    "from astropy.visualization import quantity_support\n",
    "quantity_support()\n",
    "\n",
    "# notebook gives interactive plots but not until the kernel is done\n",
    "%matplotlib notebook\n",
    "# inline gives non-interactive plots right away\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default assumption is that notebook is being run by hand\n",
    "autorun = False\n",
    "run_Ftest = True  # Set to False if you don't need F-tests and want a faster notebook run!\n",
    "check_excision = True\n",
    "\n",
    "if not autorun:\n",
    "    run_noise_analysis = False \n",
    "    use_existing_noise_dir = True\n",
    "    use_toa_pickle = True\n",
    "else:\n",
    "    run_noise_analysis = True \n",
    "    use_existing_noise_dir = False\n",
    "    use_toa_pickle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.setLevel(\"INFO\") # Set desired verbosity of log statements (DEBUG/INFO/WARNING/ERROR)\n",
    "log_to_file = False\n",
    "\n",
    "if pint.__version__ > '0.8.6':  # see https://github.com/nanograv/PINT/blob/master/CHANGELOG.md\n",
    "    pint.logging.setup(level=\"WARNING\", usecolors=True)\n",
    "\n",
    "lu.git_config_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# develop/update \\[prenoise\\] timing solution\n",
    "\n",
    "Load configuration (`.yaml`) file, get TOAs and timing model; if you're running from the root of the git distribution, simply edit the `.yaml` file name, otherwise include relevant paths to the `.yaml` file, and `.par`/`.tim` directories as kwargs (see commented example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"configs/[psr_name].[nb or wb].yaml\"  # fill in actual path\n",
    "par_directory = None   # default location\n",
    "tim_directory = None   # default location\n",
    "tc = TimingConfiguration(config, par_directory=par_directory, tim_directory=tim_directory)\n",
    "\n",
    "using_wideband = tc.get_toa_type() == 'WB'\n",
    "\n",
    "# Use excise.tim file if it exists, else revert to raw TOAs & initial cuts\n",
    "mo,to = tc.get_model_and_toas(excised=True,usepickle=use_toa_pickle)\n",
    "if not to: mo,to = tc.get_model_and_toas(apply_initial_cuts=True)\n",
    "tc.manual_cuts(to)\n",
    "\n",
    "if log_to_file:\n",
    "    lu.log_notebook_to_file(tc.get_source(), tc.get_toa_type())\n",
    "    lu.log_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing pulse numbers ensures param changes in the model will not break phase connection\n",
    "to.compute_pulse_numbers(mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure DMX windows are calculated properly, set non-binary epochs to the center of the data span\n",
    "to = du.setup_dmx(mo,to,frequency_ratio=tc.get_fratio(),max_delta_t=tc.get_sw_delay())\n",
    "lu.center_epochs(mo,to)\n",
    "if not autorun: to.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run basic checks for pulsar name, solar system ephemeris, clock correction, ecliptic coordinates, tropospheric delays, planet Shapiro delays, and if applicable, removal of Arecibo data affected by bad LO. Check that TOAs being used are from the latest `toagen` release. Also check for the appropriate number of receiver JUMPs and DMJUMPs and fix them automatically if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.check_settings(mo,to)\n",
    "\n",
    "receivers = lu.get_receivers(to)\n",
    "lu.add_feJumps(mo,receivers)\n",
    "if using_wideband:\n",
    "    lu.add_feDMJumps(mo,receivers)\n",
    "pc.check_jumps(mo,receivers,toa_type=tc.get_toa_type())\n",
    "\n",
    "if not autorun: check_recentness_excision(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fitter object and plot pre-fit residuals\n",
    "fo = tc.construct_fitter(to,mo)\n",
    "pu.plot_residuals_time(fo, restype='prefit')\n",
    "if mo.is_binary:\n",
    "    pu.plot_residuals_orb(fo, restype='prefit')\n",
    "if using_wideband:\n",
    "    pu.plot_dm_residuals(fo, restype='prefit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that free-params follow NANOGrav conventions, fit\n",
    "fo.model.free_params = tc.get_free_params(fo)\n",
    "lu.check_fit(fo,skip_check=tc.skip_check)\n",
    "\n",
    "try:\n",
    "    fo.fit_toas(maxiter=tc.get_niter())\n",
    "    fo.model.CHI2.value = fo.resids.chi2\n",
    "except ConvergenceFailure:\n",
    "    run_Ftest = False\n",
    "    log.warning('Failed to converge; moving on with best result, but should address before final version.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot post-fit residuals, print summary of results, write prenoise solution\n",
    "pu.plot_residuals_time(fo, restype='postfit')\n",
    "if mo.is_binary:\n",
    "    pu.plot_residuals_orb(fo, restype='postfit')\n",
    "if using_wideband:\n",
    "    pu.plot_dm_residuals(fo, restype='postfit')\n",
    "    \n",
    "if not autorun: fo.print_summary()\n",
    "lu.check_convergence(fo)\n",
    "\n",
    "lu.write_par(fo,toatype=tc.get_toa_type(),addext='_prenoise',include_date=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[noise\\] analysis, re-fit\n",
    "\n",
    "Noise analysis runs are required for the 15-yr v1.0 data set, using the latest available timing model and set of TOAs. If TOA excision or free parameters are changed in the `.yaml`/`.par` file(s), new noise model parameters should be generated before proceeding. Use the [prenoise] section of this notebook to improve TOA excision, ensure residuals are flat, then submit a merge request with that solution, and wait for noise results to be made available. See the \"Automatic Runs on Thorny Flats\" wiki to request new runs, or make a note for your pulsar(s) in the who-which page.\n",
    "\n",
    "We strongly discourage running noise analyses from on the notebook server, since doing so can take several hours (or days!) to complete and hogs lots of shared resources. Set `run_noise_analysis = False` unless you have a good reason to do otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dir = None   # fill in directory name here if appropriate\n",
    "compare_noise_dir = None   # fill in directory name here if appropriate\n",
    "fo_noise = fo      # fallback in case the noise model can't be found\n",
    "if noise_dir is not None:\n",
    "    tc.config['intermediate-results']['noise-dir'] = noise_dir\n",
    "if compare_noise_dir is not None:\n",
    "    tc.config['intermediate-results']['compare-noise-dir'] = compare_noise_dir\n",
    "print(f\"Looking for noise chains in {tc.get_noise_dir()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not autorun: check_recentness_noise(tc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `run_noise_analysis = True`, perform noise modeling using enterprise and enterprise_extensions; this cell will take a long time to run. Status can be monitored once modeling is 1% complete. New noise parameters will be added to the timing model if there are existing results or `model_noise` is run. Redefine the fitter object (`fo`), now with noise parameters, and re-fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_noise_analysis or use_existing_noise_dir:\n",
    "    mo_new = copy.deepcopy(mo)\n",
    "    lu.remove_noise(mo_new)\n",
    "    nu.model_noise(mo_new, to,\n",
    "                   using_wideband = using_wideband,\n",
    "                   run_noise_analysis = run_noise_analysis,\n",
    "                   model_kwargs=tc.config['noise_run']['model'],\n",
    "                   sampler_kwargs=tc.config['noise_run']['inference'],\n",
    "    )\n",
    "    try:\n",
    "        mo_new = nu.add_noise_to_model(mo_new, using_wideband = using_wideband, base_dir=tc.get_noise_dir(), \n",
    "                                       compare_dir=tc.get_compare_noise_dir(), no_corner_plot=tc.get_no_corner())\n",
    "        \n",
    "    except OSError as e:\n",
    "        log.warning(f\"Unable to read noise chains from {tc.get_noise_dir()}: {e}\")\n",
    "    else:\n",
    "        mo = mo_new\n",
    "        fo_noise = tc.construct_fitter(to,mo)\n",
    "        fo_noise.model.free_params = tc.get_free_params(fo_noise)\n",
    "        \n",
    "        try:\n",
    "            fo_noise.fit_toas(maxiter=tc.get_niter())\n",
    "            fo_noise.model.CHI2.value = fo_noise.resids.chi2\n",
    "        except ConvergenceFailure:\n",
    "            run_Ftest = False\n",
    "            log.warning('Failed to converge; moving on with best result, but should address before final version.')\n",
    "        \n",
    "        pu.plot_residuals_time(fo_noise, restype='postfit')\n",
    "        if mo.is_binary:\n",
    "            pu.plot_residuals_orb(fo_noise, restype='postfit')\n",
    "        if not autorun: fo_noise.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write par, tim, dmx files\n",
    "outpar = None  # None leads to default string value\n",
    "lu.write_par(fo_noise,toatype=tc.get_toa_type(),outfile=outpar,include_date=True)\n",
    "\n",
    "to.table = to.orig_table # resurrect cut TOAs to write, commented\n",
    "fo_cuts = tc.construct_fitter(to,mo)\n",
    "outtim = None  # None leads to default string value\n",
    "lu.write_tim(fo_cuts,toatype=tc.get_toa_type(),outfile=outtim,commentflag='cut')\n",
    "apply_cut_select(to,reason='resumption after write_tim') # de-select cut TOAs once again\n",
    "\n",
    "dmx_dict = dmxparse(fo_noise, save=\"dmxparse.out\")  # requires DMX bins in model to run properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check [excision] results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the percentage of good TOAs compared to automatically and manually excised TOAs. An excision \"donut\" plot will be included in the notebook as well as a warning if lots of TOAs have been excised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_dict = None\n",
    "if check_excision:\n",
    "    cuts_dict = lu.cut_summary(to, tc, print_summary=True, save=True)\n",
    "    lu.plot_cuts_all_backends(to, save=True, using_wideband=using_wideband, source_name=tc.get_source())\n",
    "    lu.highlight_cut_resids(to, mo, tc, ylim_good=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[compare\\] to previous timing model\n",
    "\n",
    "Compare post-fit model to `compare-model` (or pre-fit model, if `compare-model` is not specified in the `.yaml` file). Use `?mo.compare` for more information about verbosity options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.compare_models(fo_noise,\n",
    "               model_to_compare=tc.get_compare_model(),\n",
    "               verbosity='check',\n",
    "               nodmx=True,\n",
    "               threshold_sigma=3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check parameter \\[significance\\]\n",
    "\n",
    "Get information on the weighted (W)RMS residuals per backend. Set `epoch_avg = True` to get the (W)RMS of the epoch-averaged residuals (does not work for wideband analysis; the timing model must have `ECORR` in order for epoch averaging to work). Set `whitened = True` to get the (W)RMS of the whitened residuals. Set both to `True` to get the (W)RMS of the whitened, epoch-averaged residuals.\n",
    "\n",
    "For wideband analysis, set `dm_stats = True` to also return the (W)RMS of the DM residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_dict = None\n",
    "epoch_avg = 'ecorr_noise' in fo_noise.model.get_components_by_category()\n",
    "if not using_wideband:\n",
    "    rs_dict = resid_stats(fo_noise, \n",
    "                          epoch_avg=epoch_avg,\n",
    "                          whitened=True, \n",
    "                          print_pretty=True)\n",
    "else:\n",
    "    rs_dict, dm_dict = resid_stats(fo_noise, \n",
    "                                   whitened=True, \n",
    "                                   dm_stats=True, \n",
    "                                   print_pretty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run F-tests to check significance of existing/new parameters; `alpha` is the p-value threshold for rejecting the null hypothesis that a parameter is not significant. This cell may take 5-10 minutes to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ftest_dict = None\n",
    "if run_Ftest:\n",
    "    savedLevel = log.getEffectiveLevel()\n",
    "    try:\n",
    "        log.setLevel(\"WARNING\")\n",
    "        Ftest_dict = run_Ftests(fo_noise, \n",
    "                                alpha=0.0027, \n",
    "                                NITS=tc.get_niter())\n",
    "    finally:\n",
    "        log.setLevel(savedLevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate \\[summary\\] pdf\n",
    "\n",
    "Generate summary plots required for pdf summaries. Note: this cell will output white space for the plots, but will save them and incorporate them into the pdf summaries appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not using_wideband:\n",
    "    pu.plots_for_summary_pdf_nb(fo_noise)\n",
    "else:\n",
    "    pu.plots_for_summary_pdf_wb(fo_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARFILE = os.path.join(tc.par_directory,tc.config[\"timing-model\"])\n",
    "pdf_writer(fo, PARFILE, rs_dict, \n",
    "           Ftest_dict=Ftest_dict, \n",
    "           dm_dict=dm_dict, \n",
    "           previous_parfile=tc.get_compare_model(), \n",
    "           fitter_noise=fo_noise,\n",
    "           cuts_dict=cuts_dict,\n",
    "           no_corner=tc.get_no_corner())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[changelog\\] entries\n",
    "\n",
    "New changelog entries in the `.yaml` file should follow a specific format and are only added for specified reasons (excising TOAs, adding/removing params, changing binary models, etc.). For more detailed instructions, run `lu.new_changelog_entry?` in a new cell. This function can be used to format your entry, which should be added to the bottom of the appropriate `.yaml` file. Note: make sure your git `user.email` is properly configured, since this field is used to add your name to the entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
